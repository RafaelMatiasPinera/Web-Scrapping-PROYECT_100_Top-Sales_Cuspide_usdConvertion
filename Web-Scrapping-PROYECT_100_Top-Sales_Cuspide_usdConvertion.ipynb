{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical Proposal:\n",
    "\n",
    "Perform web scraping on the Cúspide Libros website, www.cuspide.com, to obtain the list of the top 100 best-selling books of the week. \n",
    "The data to collect includes: book title, book URL, price in pesos, price in dollars, \n",
    "and price in dollars considering the exchange rate of the Argentine blue dollar or in euros, along with the date. \n",
    "The exchange rate for the Argentine blue dollar or in euros will also be obtained through scraping from a selected web page.\n",
    "\n",
    "These data will be stored in a .csv file with the corresponding fields. \n",
    "Additionally, another output file will be created as an error log in case scraping for any title cannot be performed for some reason. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index:\n",
    "# 0- Import libraries\n",
    "# 1- Scraping and create a dictionary of Books and URLs\n",
    "# 2- Published price in pesos\n",
    "# 3- Published price on each page, in dollars\n",
    "# 4- BLUE (Exchange rate)\n",
    "# 5- Date\n",
    "# 6- Combine everything into a data frame\n",
    "# 7- EXPORT to .CSV\n",
    "# 8- Output file, error log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0\n",
    "# import libraries\n",
    "import requests\n",
    "import re\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "# select the website for the top 100 best sellers on Cúspide and set variables for scraping\n",
    "website = \"https://cuspide.com/100-mas-vendidos/\"\n",
    "resultado0 = requests.get(website)\n",
    "content = resultado0.text\n",
    "\n",
    "# Create BeautifulSoup object\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "# Find all <h3> tags\n",
    "nlibros = soup.find_all('h3', class_='name product-title woocommerce-loop-product__title')\n",
    "\n",
    "lista_Titulodellibro = []\n",
    "lista_Url = []\n",
    "\n",
    "# Iterate over the list of BeautifulSoup objects\n",
    "for h3_element in nlibros:\n",
    "    # Find the <a> tag within <h3>\n",
    "    a_element = h3_element.find('a')\n",
    "\n",
    "    # Check if the <a> tag was found\n",
    "    if a_element:\n",
    "        # Print the text inside the <a> tag\n",
    "        titulo_libro = a_element.get_text(strip=True)\n",
    "        lista_Titulodellibro.append (titulo_libro)\n",
    "        \n",
    "        # get the URL\n",
    "        url_libro = a_element['href']\n",
    "        lista_Url.append (url_libro)\n",
    "    else:\n",
    "        print(\"The <a> tag was not found within the <h3> element\")\n",
    "\n",
    "# create dictionaries\n",
    "diccionario_Titulos = {'Titulos' : lista_Titulodellibro}\n",
    "diccionario_Url = { 'URL' : lista_Url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Price of the books published on the page (in pesos)\n",
    "listadesordenada = soup.find_all ('span', class_='woocommerce-Price-amount')\n",
    "lista_preciodellibro = []\n",
    "\n",
    "for precio in listadesordenada:\n",
    "    # Find the <a> tag within <h3>\n",
    "    a_element = precio.find('bdi')\n",
    "\n",
    "    if a_element:\n",
    "        # Print the text inside the <a> tag\n",
    "        precio_libro = a_element.get_text(strip=True)\n",
    "        lista_preciodellibro.append (precio_libro)\n",
    "listaprecios = lista_preciodellibro[1:]\n",
    "# I shifted it one to the right because it was taking the value of the shopping cart, which we are not going to consider.\n",
    "\n",
    "#create the dictionary\n",
    "diccionario_precio_en_pesos = {'Precio en pesos' : listaprecios}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3- Published price on each page, in dollars.\n",
    "lista_precioendolares = []\n",
    "\n",
    "for i in lista_Url:\n",
    "    resultado = requests.get(i)\n",
    "    contenido = resultado.text\n",
    "    soup = BeautifulSoup(contenido, 'lxml')\n",
    "    preciodolar = soup.find_all('span', style= 'font-size: 1.3em')\n",
    "    x = str (preciodolar)\n",
    "    y = x.split(\">\")[1].split(\"<\")[0]\n",
    "    lista_precioendolares.append(f'USD${y}')\n",
    "\n",
    "#create the dictionary\n",
    "diccionario_dolares = {'En USD (publicado)':lista_precioendolares}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4- VALUE OF THE BOOKS IN BLUE DOLLAR\n",
    "\n",
    "web = 'https://dolarhoy.com/cotizaciondolarblue'\n",
    "resultado = requests.get(web)\n",
    "contenido = resultado.text\n",
    "soup = BeautifulSoup(contenido, 'lxml')\n",
    "dolarblue = soup.find_all('div', class_= 'value')\n",
    "\n",
    "blue = list (dolarblue)\n",
    "blue = str(blue[1])\n",
    "dolarblue = (blue.split(\">\")[1].split(\"<\")[0])\n",
    "\n",
    "def calcularpreciodivision(x, y):\n",
    "    x = x.replace (\".\", \"\")\n",
    "    x = x.replace (\",\", \".\")\n",
    "    x = x.replace (\"$\", \"\")\n",
    "    x = float (x)\n",
    "    y = y.replace(\",\", \".\")\n",
    "    y = y.replace(\"$\",\"\")\n",
    "    y = float(y)\n",
    "    return ( x / y)\n",
    "\n",
    "lista_valorblue =[]\n",
    "for i in listaprecios:\n",
    "    x = calcularpreciodivision (i,dolarblue)\n",
    "    redondeado = round(x, 2)\n",
    "    lista_valorblue.append(f'blue_USD: ${redondeado}')\n",
    "\n",
    "#create the dictionary\n",
    "diccionario_blue = {'En USD BLUE' : lista_valorblue}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Date \n",
    "from datetime import datetime\n",
    "# Get the date\n",
    "fecha_actual = datetime.now()\n",
    "\n",
    "lista_fechas = []\n",
    "for i in listaprecios:\n",
    "    lista_fechas.append(fecha_actual.strftime(\"%d-%m-%Y\"))\n",
    "\n",
    "diccionario_fechas = {'fecha' : lista_fechas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6- Combine everything into a data frame\n",
    "df0 = diccionario_Titulos\n",
    "df1 = diccionario_Url\n",
    "df2 = diccionario_precio_en_pesos\n",
    "df3 = diccionario_dolares\n",
    "df4 = diccionario_blue\n",
    "df5 = diccionario_fechas\n",
    "df = df0 | df1 | df2 | df3| df4| df5\n",
    "df = pd.DataFrame (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "df.to_csv('cuspide-100-mas-vendidos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "logging.basicConfig(level = logging.INFO, filename=\"log.log\", filemode = \"w\")\n",
    "logging.debug(\"debug\")\n",
    "logging.info(\"info\")\n",
    "logging.warning(\"warning\")\n",
    "logging.error(\"error\")\n",
    "logging.critical(\"critical\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "416506a27804378c8c738f285bf8af7dae276a0ed750831d865624319d7e3180"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
